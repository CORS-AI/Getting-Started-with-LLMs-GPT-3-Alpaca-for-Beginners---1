{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e56875",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1824d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read the Excel file\n",
    "file_path = 'food.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Select the 'fdc_id' and 'description' columns from the first Excel file\n",
    "selected_columns1 = data[['fdc_id', 'description']]\n",
    "\n",
    "# Read the second Excel file\n",
    "file_path2 = 'input_food.csv'\n",
    "data2 = pd.read_csv(file_path2)\n",
    "\n",
    "# Select the 'fdc_id' and 'sr_description' columns from the second Excel file\n",
    "selected_columns2 = data2[['fdc_id', 'sr_description']]\n",
    "\n",
    "# Rename the 'sr_description' column to 'description'\n",
    "selected_columns2 = selected_columns2.rename(columns={'sr_description': 'description'})\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "combined_data = pd.concat([selected_columns1, selected_columns2], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the combined data to a new Excel file\n",
    "output_file_path = 'combined_excel_file.xlsx'\n",
    "\n",
    "combined_data.to_excel(output_file_path, index=False)\n",
    "\n",
    "# Read the 'food_nutrient' Excel file\n",
    "food_nutrient_file_path = 'food_nutrient.csv'\n",
    "food_nutrient_data = pd.read_csv(food_nutrient_file_path)\n",
    "\n",
    "# Read the 'nutrient' Excel file\n",
    "nutrient_file_path = 'nutrient.csv'\n",
    "nutrient_data = pd.read_csv(nutrient_file_path)\n",
    "\n",
    "# Merge 'food_nutrient_data' with 'nutrient_data' on the nutrient_id/id\n",
    "merged_data = food_nutrient_data.merge(nutrient_data, left_on='nutrient_id', right_on='id')\n",
    "\n",
    "# Group the data by 'fdc_id' and aggregate the nutrient names, units, and amounts as lists\n",
    "grouped_data = merged_data.groupby('fdc_id').agg(\n",
    "    nutrients=pd.NamedAgg(column='name', aggfunc=list),\n",
    "    units=pd.NamedAgg(column='unit_name', aggfunc=list),\n",
    "    amounts=pd.NamedAgg(column='amount', aggfunc=list)\n",
    ").reset_index()\n",
    "\n",
    "# Merge 'combined_data' with 'grouped_data' on the 'fdc_id' column\n",
    "final_data = combined_data.merge(grouped_data, on='fdc_id')\n",
    "\n",
    "# Save the final data to a new Excel file\n",
    "final_output_file_path = 'final_excel_file.xlsx'\n",
    "\n",
    "final_data.to_excel(final_output_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ddfd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the final Excel file\n",
    "final_excel_file_path = 'final_excel_file.xlsx'\n",
    "final_data = pd.read_excel(final_excel_file_path)\n",
    "\n",
    "# Create a new DataFrame with two columns: 'input_text' and 'target_text'\n",
    "new_data = pd.DataFrame(columns=['input_text', 'target_text'])\n",
    "\n",
    "# Assign the 'description' column to the 'input_text' column\n",
    "new_data['input_text'] = final_data['description']\n",
    "\n",
    "# Concatenate the 'nutrients', 'units', and 'amounts' columns into a single string for each row\n",
    "# and assign it to the 'target_text' column\n",
    "new_data['target_text'] = final_data['nutrients'].astype(str) + ', ' + \\\n",
    "                          final_data['units'].astype(str) + ', ' + \\\n",
    "                          final_data['amounts'].astype(str)\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "new_csv_file_path = 'input_target_data.csv'\n",
    "new_data.to_csv(new_csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06503726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We then use Open AI CLI from windows command to fine tune the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dee5815",
   "metadata": {},
   "source": [
    "For cli:\n",
    "\n",
    "- Open Windows shell/command. Ensure openai cli is installed and in the correct path as your data folder. \n",
    "\n",
    "- Export open ai key using env or directly. You can get a API KEY on OPEN AI site after registering.\n",
    "\n",
    "\t\n",
    "\tpython export OPENAI_API_KEY= <OPENAI KEY>\n",
    "\n",
    "(refer to the documentation for more info but find your code mgiht need some playing around with)\n",
    "\n",
    "\n",
    "- This cli tool checks the data to see if it needs further cleaning.\n",
    "    \n",
    "\n",
    "\topenai tools fine_tunes.prepare_data -f <Your data file full path>\n",
    "\n",
    "\n",
    "- Once the client tool check completes, either it okays the current file or creates a new one. If a new one is created ensure that name is reflecte in below code. This code starts the fine tune process.\n",
    "\n",
    " \tset OPENAI_API_KEY= <Key> && openai api fine_tunes.create -t  C:\\Users\\tm568\\OneDrive\\Desktop\\Codes\\GPT_Python_Test\\latest_filtered_input_target_data_prepared_prepared.jsonl\n",
    "\n",
    "\n",
    "\n",
    "- To check status use\n",
    "    \n",
    "    openai api fine_tunes.follow -i <Model id>\n",
    "\n",
    "\n",
    "-  To see the list of fine_tunes, their status, which files you used to train them. \n",
    "    \n",
    "    openai api fine_tunes.list\n",
    "\n",
    "    \n",
    "    \n",
    "- Documentation: \n",
    "   \n",
    "    https://platform.openai.com/docs/guides/fine-tuning\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
